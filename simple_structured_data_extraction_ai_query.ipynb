{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -3258929192892811,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "575b08b5-aa8a-4acd-a4a1-9cd8c6f823fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 例: 構造化データ抽出、バッチ推論、および評価\n",
    "このノートブックは、`ai_query` ([AWS](https://docs.databricks.com/aws/ja/sql/language-manual/functions/ai_query) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/sql/language-manual/functions/ai_query)) を使用して基本的な構造化データ抽出を実行する方法を示します。\n",
    "\n",
    "このプロセスは、生の非構造化データを自動抽出技術を通じて効果的に整理された実用的な情報に変換する方法を説明します。\n",
    "\n",
    "このノートブックは、Mosaic AI Agent Evaluation ([AWS](https://docs.databricks.com/aws/ja/generative-ai/agent-evaluation) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/generative-ai/agent-evaluation/)) を活用して、正解データが利用可能な場合の精度を評価する方法も示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cb592d2-1ba2-4453-bc8a-9fb5686a0b56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow databricks-agents\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -3258929192892811,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba2d1f1-d47b-4906-a7ca-7906003e14e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## `ai_query` を使用したバッチ推論の実行\n",
    "このノートブックでは、構造化データ抽出のために `ai_query` を使用する方法を示すために、雇用契約のシミュレートされたデータセットを作成します。このダミーデータセットは、雇用者および従業員の名前などの重要な情報に焦点を当てたエンティティ抽出のテストベッドとして機能します。抽出されるデータの真実の値が含まれており、後で評価に使用されます。\n",
    "\n",
    "次に、このノートブックでは、このデータセットを使用して `ai_query` ([AWS](https://docs.databricks.com/aws/ja/sql/language-manual/functions/ai_query) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/sql/language-manual/functions/ai_query)) を使用したバッチ推論を実施します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e86576bd-4025-42eb-ad0b-155745401f6b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Dummy contract data"
    }
   },
   "outputs": [],
   "source": [
    "# ダミーの雇用契約とその正解データ\n",
    "employment_contracts = [\n",
    "    dict(\n",
    "        contract_text=\"この雇用契約は2023年5月15日にTechCorp Inc.（以下「雇用主」）とSarah Johnson（以下「従業員」）の間で締結されます。従業員は2023年6月1日からソフトウェアエンジニアとして勤務を開始し、年俸は85,000ドルです。従業員は3か月の試用期間に同意します。\",\n",
    "        ground_truth='{\"signature_date\": \"2023年5月15日\", \"employer\": \"TechCorp Inc.\", \"employee\": \"Sarah Johnson\", \"bonuses\": [\"N/A\"]}'\n",
    "    ),\n",
    "    dict(\n",
    "        contract_text=\"雇用契約：2023年7月1日付で、DataSystems LLC（以下「雇用主」）はMichael Chen（以下「従業員」）をデータアナリストとして雇用することに同意します。従業員の初任給は年俸70,000ドルです。この契約には、終了後12か月間有効な競業避止条項が含まれています。\",\n",
    "        ground_truth='{\"signature_date\": \"2023年7月1日\", \"employer\": \"DataSystems LLC\", \"employee\": \"Michael Chen\", \"bonuses\": [\"N/A\"]}'\n",
    "    ),\n",
    "    dict(\n",
    "        contract_text=\"2023年8月15日、CloudNet Solutions（「雇用主」）とEmma Rodriguez（「従業員」）はこの雇用契約を締結します。従業員はネットワーク管理者として2023年9月1日に勤務を開始します。年俸は78,000ドルで、5,000ドルのサインボーナスがあります。\",\n",
    "        ground_truth='{\"signature_date\": \"2023年8月15日\", \"employer\":\"CloudNet Solutions\", \"employee\": \"Emma Rodriguez\", \"bonuses\":[\"5,000ドルのサインボーナス\"]}'\n",
    "    ),\n",
    "    dict(\n",
    "        contract_text=\"この契約は2023年10月1日付で、AI Innovations Corp（「雇用主」）とDr. James Lee（「従業員」）の間で締結されます。Dr. Leeは主任研究科学者として2023年11月1日に就任します。基本給は年俸150,000ドルで、業績に基づくボーナスは付録Aに記載されています。\",\n",
    "        ground_truth='{\"signature_date\": \"2023年10月1日\", \"employer\": \"AI Innovations Corp\", \"employee\": \"Dr. James Lee\", \"bonuses\":[\"付録Aに記載された業績に基づくボーナス\"]}'\n",
    "    ),\n",
    "]\n",
    "\n",
    "employment_contracts_df = spark.createDataFrame(employment_contracts)\n",
    "employment_contracts_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -3258929192892811,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c6d39d-68f2-4ccb-be50-d59f5f0d99fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### `ai_query` を使用した構造化データ抽出\n",
    "次のセルでは、`ai_query` を使用して構造化データ抽出を実行するために必要な主な入力を定義します:\n",
    "- LLM エンドポイント名\n",
    "- データ抽出を実行し、JSON を応答形式として使用するように LLM に指示するプロンプト\n",
    "- 応答の JSON スキーマ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f22cede9-ef45-4b66-a8a9-4cf9699b5745",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define prompt and response format"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "\n",
    "PROMPT = \"\"\"あなたは法的文書の分析に特化したAIアシスタントです。\n",
    "あなたのタスクは、与えられた契約書から関連情報を抽出することです。\n",
    "出力は構造化されたJSONオブジェクトでなければなりません。\n",
    "\n",
    "指示:\n",
    "1. このプロンプトの最後に提供される契約書全体を注意深く読んでください。\n",
    "2. 関連情報を抽出してください。\n",
    "3. 以下に指定された形式のJSONで結果を提示してください。\n",
    "\n",
    "重要な注意事項:\n",
    "- 関連情報のみを抽出してください。\n",
    "- 契約全体の文脈を考慮して関連性を判断してください。\n",
    "- 冗長にならず、正しい形式と情報のみを返してください。\n",
    "- 一部の質問には関連する抜粋がない場合があります。その場合は、期待される型に応じて \"N/A\" または [\"N/A\"] を返してください。\n",
    "- ここに記載されているJSONキー以外は含めないでください。\n",
    "- 同じキーをJSONに複数回含めないでください。\n",
    "\n",
    "期待されるJSONキーとその説明:\n",
    "- signature_date: 契約の署名日。\n",
    "- employer: 雇用主の名前。\n",
    "- employee: 従業員の名前。\n",
    "- bonuses: 記載されている特定のボーナスのリスト。\n",
    "\n",
    "分析する契約書:\n",
    "\"\"\"\n",
    "\n",
    "response_format = json.dumps({\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"employment_contract_extraction\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"signature_date\": {\"type\": \"string\"},\n",
    "                \"employer\": {\"type\": \"string\"},\n",
    "                \"employee\": {\"type\": \"string\"},\n",
    "                \"bonuses\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "            },\n",
    "            \"strict\": True,\n",
    "        },\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -3258929192892811,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0185df1c-26ae-431a-9826-f172b0879f8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### バッチ推論\n",
    "以下では、上記で定義された入力を使用して、`ai_query` を SQL 式として Spark データフレームに適用します。LLM の応答である JSON 文字列を解析して、個々のデータポイントを抽出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "291acda3-7f47-4763-8a56-a484e0f28dfc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use ai_query for batch inference"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_json\n",
    "\n",
    "# クエリを定義\n",
    "ai_query_expr = f\"\"\"\n",
    "  ai_query(\n",
    "    endpoint => '{LLM_ENDPOINT_NAME}',\n",
    "    request => CONCAT('{PROMPT}', contract_text),\n",
    "    responseFormat => '{response_format}',\n",
    "    modelParameters => named_struct('temperature', 0.)\n",
    "    ) AS response\n",
    "  \"\"\"\n",
    "\n",
    "# 解析したいLLMレスポンス文字列のJSONスキーマ\n",
    "json_schema = \"STRUCT<signature_date STRING, employee STRING, employer STRING, bonuses ARRAY<STRING>>\"\n",
    "\n",
    "# バッチクエリを実行し、レスポンスを解析\n",
    "employment_contracts_df = employment_contracts_df.selectExpr(\n",
    "    \"*\", ai_query_expr\n",
    ").withColumn(\"parsed_response\", from_json(col(\"response\"), json_schema))\n",
    "\n",
    "employment_contracts_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -3258929192892811,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a11d8c0-47a0-4e4e-8783-529e5f471257",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## エージェント評価によるエージェントの評価\n",
    "\n",
    "エージェントの品質を評価するために、エージェント評価フレームワーク ([AWS](https://docs.databricks.com/aws/ja/generative-ai/agent-evaluation) | [Azure](https://learn.microsoft.com/ja-jp/azure/databricks/generative-ai/agent-evaluation/)) を使用します。このアプローチでは、正確性判定を使用して、期待されるエンティティ（または事実）と実際の応答を比較し、エージェントのパフォーマンスを包括的に評価します。\n",
    "\n",
    "_注: 別のアプローチとして、個々のエンティティに対して `recall` や `precision` などのメトリクスを計算する方法もありますが、これには追加のデータ変換や [カスタムメトリクス](https://mlflow.org/docs/latest/python_api/mlflow.metrics.html#mlflow-metrics) が必要です。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58008171-5c70-45a1-9a2d-91ad7d396827",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from pyspark.sql.functions import split\n",
    "\n",
    "# mlflow.evaluate() が期待する評価用データフレームを準備\n",
    "eval_pdf = employment_contracts_df.select(\n",
    "    col(\"contract_text\").alias(\"request\"),\n",
    "    col(\"response\"),\n",
    "    split(\"ground_truth\", \",\").alias(\"expected_facts\"),\n",
    ").toPandas()\n",
    "\n",
    "# 評価を実行し、結果を mlflow 実験に記録\n",
    "with mlflow.start_run():\n",
    "    results = mlflow.evaluate(\n",
    "        data=eval_pdf,\n",
    "        model_type=\"databricks-agent\",\n",
    "        evaluator_config={\n",
    "            \"databricks-agent\": {\n",
    "                \"metrics\": [\"correctness\"],  # 正確性の評価のみ有効化\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc3e0374-a78b-470b-925b-92be3ab9a329",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 次のステップ\n",
    "Databricksでの構造化データ抽出に関するさらなる洞察と関連する例については、以下の包括的な技術ブログ投稿を参照してください:\n",
    "- [LLMを使用したエンドツーエンドの構造化抽出 – パート1: バッチエンティティ抽出](https://community.databricks.com/t5/technical-blog/end-to-end-structured-extraction-with-llm-part-1-batch-entity/ba-p/98396)\n",
    "- [LLMを使用したエンドツーエンドの構造化抽出 – パート2: 合成データを用いたファインチューニング](https://community.databricks.com/t5/technical-blog/end-to-end-structured-extraction-with-llm-part-2-fine-tuning/ba-p/99900)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1335034106274547,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "simple_structured_data_extraction_ai_query",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
